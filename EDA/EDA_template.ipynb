{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12abf911-fdb0-4366-9432-06890e6583bb",
   "metadata": {},
   "source": [
    "<b>Web Scraping Steam Reviews for Exploratory Data Analysis</b>\n",
    "\n",
    "This application will scrape the user reviews of a given Steam game. It will return a specified amount of reviews of a specified game. For each review, the application will grab the following information:\n",
    "- User name\n",
    "- User ID\n",
    "- User Country (If publically available to the steam api)\n",
    "- Date of the review\n",
    "- Rating of the review\n",
    "- Text content of the review\n",
    "\n",
    "This information is then stored into a json file to be used later on for analyzing trends in user reviews.\n",
    "\n",
    "I have included the interesting examples that I previously gather using the selenium version of my program. There are the JSON files for the following games:\n",
    "'Antonblast' (app_id = 1887400)\n",
    "'Marvel Rivals' (app_id = 2767030)\n",
    "'Overwatch 2' (app_id = 2357570)\n",
    "\n",
    "With 'Antonblast', I show off an example of using the stored text content of the reviews to create a word cloud using the wordcloud library, I found this to be probably one of the most interesting uses of this sort of data as having speedy access to what it is everyone is actually talking about when reviewing a game can help to give a good idea of the main points of the game, both positive and negative.\n",
    "\n",
    "I also decided to create a pie chart based off the country of the user that posted the review. Mainly I just wanted to ensure I was using the data that I used the Steam API to gather instead of pure web scraping. Considering many users do not display their country publically, I thought of two ways I could deal with this when presenting the data.\n",
    "1. I could go ahead and just group countries that were marked as private with the other category to display on the pie chart\n",
    "2. I could just omit private countries from the data for the pie chart allowing a better look at countries that were actually available\n",
    "\n",
    "I decided to go with the latter as I felt increasing the size of the 'Other' field would cause the data to be less accurate since it would shrink entries like the USA and it is a safe assumption that many of the private countries will be from the USA.\n",
    "I decided to represent this data mainly because 'Antonblast' is a game from a small indie studio which most likely has a rather small marketting budget therefore I wanted to see what the global spread of reviews would look like.\n",
    "\n",
    "Lastly, I decided to compare two games against eachother using a stacked bar graph. These games were 'Marvel Rivals' and 'Overwatch 2'. I went ahead and scraped a large sample of reviews from the both of them (3000 of the most recent reviews from each). I then went ahead and plotted them on the bar graph to directly compare the proportion of negative reviews to positive reviews. The relationship between the games would make this an interesting comparison seeing as at this point in time, 'Marvel Rivals' is being hailed as the better 'Overwatch'. Interestingly, the gap between the two was not as extreme as I had first predicted, though it is still there. \n",
    "\n",
    "For most of the earlier lectures in the second term, I was already aware of web scraping techniques due to my prior experience in developing a tool for data gathering for Curve Games, however I did not know much in the way of presenting and vizualising data so the later weeks were quite helpful for me, especially the ones covering pandas databases and the matplot library.\n",
    "\n",
    "An advanced technique I used was employing the use of Selenium. This was necessary for what I wanted to d as Steam's review page makes use of an infinite scroll set up. This means that in order to load more than ten reviews, I would need to have some form of interaction with the webpage. Since BeautifulSoup and requests wouldn't be enough for this, I decided to use Selenium and ChromeDriver.\n",
    "\n",
    "The data is retrieved via a combination of webscraping and use of the Steam API. I scrape elements such as the user's display name and id as well as the review date, text content, and rating. I can then use the id to retreive further data about the user through the Steam Api. I use this to access their country without the need to load their profile in ChromeDriver which would slow down the Application immensely. I also grab details aout the review via web scraping as this stuff would not be available through Steam's API.\n",
    "Please see:\n",
    "https://steamcommunity.com/robots.txt\n",
    "https://steamcommunity.com/dev\n",
    "https://pypi.org/project/python-steam-api/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484e33a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Here is the version of the code that uses just BeautifulSoup4 and requests. It is limited in how many reviews it can scrape due to the fact that Steam utilizes infinite scroll for the reviews page, so only the first ten reviews are present upon loading the page.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c227e4dc-04e3-43ac-a684-085844efead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from steam_web_api import Steam\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "from dateutil import parser\n",
    "\n",
    "def date_to_computer_readable(date):\n",
    "    try:\n",
    "        parsed_date = parser.parse(date)\n",
    "    except:\n",
    "        return date\n",
    "    return parsed_date.strftime('%d-%m-%Y')\n",
    "def generateJSON(data, app_id):\n",
    "    with open(f'{app_id}.json', 'w') as new_file:\n",
    "        json.dump(data, new_file, indent=4)\n",
    "        new_file.close()\n",
    "def load_steam_api():\n",
    "    load_dotenv()\n",
    "    KEY = os.getenv('STEAM_API_KEY')\n",
    "    return Steam(KEY)\n",
    "def separate_date_and_review_content(review_box):\n",
    "    reg_remove = r\"Product refunded|Product received for free|Posted: \"\n",
    "    date = review_box.find('div', class_='date_posted').get_text().replace('Posted: ', '')\n",
    "    review = review_box.find('div', class_='apphub_CardTextContent').get_text().replace(date, '')\n",
    "    review = re.sub(reg_remove, '', review).strip()\n",
    "    date = date_to_computer_readable(date)\n",
    "    return date, review\n",
    "def create_review_object(user_name, user_ID, country, date, pos_rating, review):\n",
    "    return {\n",
    "        \"user\": user_name,\n",
    "        \"user_ID\": user_ID,\n",
    "        \"country\": country,\n",
    "        \"date\": date,\n",
    "        \"positive rating\": pos_rating,\n",
    "        \"review\": review\n",
    "    }\n",
    "def parse_review_element():\n",
    "    user = review_box.find('div', class_='apphub_CardContentAuthorName')\n",
    "    user_ID = user.find('a').get('href').split('/')[-2] \n",
    "    date, review = separate_date_and_review_content(review_box)\n",
    "    pos_rating = True if 'icon_thumbsUp' in review_box.find('div', class_='thumb').find('img').get('src') else False\n",
    "    try:\n",
    "        country = steam.users.get_user_details(user_ID)['player']['loccountrycode']\n",
    "    except:\n",
    "        country = 'Private' \n",
    "    return create_review_object(user.get_text(), user_ID, country, date, pos_rating, review)\n",
    "\n",
    "steam = load_steam_api()\n",
    "\n",
    "app_id =int(input('Enter the app id: '))\n",
    "\n",
    "response = requests.get(f'https://steamcommunity.com/app/{app_id}/reviews/?filterLanguage=all&p=1&browsefilter=mostrecent')\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    review_boxes = soup.find_all('div', class_='apphub_Card')\n",
    "    \n",
    "    data = []\n",
    "    for review_box in review_boxes:\n",
    "        data.append(parse_review_element())\n",
    "\n",
    "    generateJSON(data, app_id)\n",
    "else:\n",
    "    print('Error: Unable to fetch data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9965eee9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Below is the version that employs the use of Selenium in order to scrape the steam reviews page while dealing with the 'infinite scroll' aspect. You'll need to ensure you have Chromedriver.exe included in this directory for it to run.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a3baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from steam_web_api import Steam\n",
    "from dateutil import parser\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def date_to_computer_readable(date):\n",
    "    try:\n",
    "        parsed_date = parser.parse(date)\n",
    "    except:\n",
    "        return date\n",
    "    return parsed_date.strftime('%d-%m-%Y')\n",
    "def generateJSON(data, app_id):\n",
    "    with open(f'{app_id}.json', 'w') as new_file:\n",
    "        json.dump(data, new_file, indent=4)\n",
    "        new_file.close()\n",
    "def create_review_object(user_name, user_ID, country, date, pos_rating, review):\n",
    "    return {\n",
    "        \"user\": user_name,\n",
    "        \"user_ID\": user_ID,\n",
    "        \"country\": country,\n",
    "        \"date\": date,\n",
    "        \"positive rating\": pos_rating,\n",
    "        \"review\": review\n",
    "    }\n",
    "def separate_date_and_review_content(review_box):\n",
    "    reg_remove = r\"Product refunded|Product received for free|Posted: \"\n",
    "    date = review_box.find_element(By.CLASS_NAME, 'date_posted').text.replace('Posted: ', '')\n",
    "    review = review_box.find_element(By.CLASS_NAME, 'apphub_CardTextContent').text.replace(date, '')\n",
    "    review = re.sub(reg_remove, '', review).strip()\n",
    "    date = date_to_computer_readable(date)\n",
    "    return date, review\n",
    "def start_chromedriver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument('--disable-extensions')\n",
    "    options.add_argument('--disable-popup-blocking')\n",
    "    options.add_argument('--profile-directory=Default')\n",
    "    options.add_argument('--disable-notifications')\n",
    "    options.add_argument('--disable-logging')\n",
    "    options.add_argument('--disable-plugins-discovery')\n",
    "    options.add_argument('--incognito')  \n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')  \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(f'https://steamcommunity.com/app/{app_id}/reviews/?filterLanguage=all&p=1&browsefilter=mostrecent')\n",
    "    return driver\n",
    "def get_infinite_scroll_reviews():\n",
    "    review_boxes = []\n",
    "    while True:\n",
    "        try:\n",
    "            review_boxes = driver.find_elements(By.CLASS_NAME, 'apphub_Card')\n",
    "            if len(review_boxes) > target_review_count:\n",
    "                break\n",
    "            if driver.find_element(By.CLASS_NAME, 'apphub_NoMoreContentText2').is_displayed():\n",
    "                break\n",
    "            driver.execute_script(\"javascript:CheckForMoreContent()\")\n",
    "        except:\n",
    "            break\n",
    "    print(str(len(review_boxes)) + \" reviews found!\")\n",
    "    return review_boxes\n",
    "def parse_review_element():\n",
    "    user = review_box.find_element(By.CLASS_NAME, 'apphub_CardContentAuthorName').text\n",
    "    user_ID = review_box.find_element(By.TAG_NAME, 'a').get_dom_attribute('href').split('/')[-2]\n",
    "    date, review = separate_date_and_review_content(review_box)\n",
    "    pos_rating = True if 'icon_thumbsUp' in review_box.find_element(By.CLASS_NAME, 'thumb').find_element(By.TAG_NAME, 'img').get_attribute('src') else False\n",
    "    try:\n",
    "        country = steam.users.get_user_details(user_ID)['player']['loccountrycode']\n",
    "    except:\n",
    "        country = 'Private'\n",
    "    return create_review_object(user, user_ID, country, date, pos_rating, review)\n",
    "def load_steam_api():\n",
    "    load_dotenv()\n",
    "    KEY = os.getenv('STEAM_API_KEY')\n",
    "    return Steam(KEY)\n",
    "\n",
    "steam = load_steam_api()\n",
    "\n",
    "app_id =int(input('Enter the app id: '))\n",
    "target_review_count = int(input('Enter the target number of reviews to scrape: '))\n",
    "\n",
    "driver = start_chromedriver()\n",
    "driver.get(f'https://steamcommunity.com/app/{app_id}/reviews/?filterLanguage=all&p=1&browsefilter=mostrecent')\n",
    "\n",
    "review_boxes = get_infinite_scroll_reviews()\n",
    "\n",
    "data = []\n",
    "for review_box in review_boxes:\n",
    "    data.append(parse_review_element())\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "generateJSON(data, app_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd2774a-bd82-48db-8323-350604a3d5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  user            user_ID  country       date  \\\n",
      "0             KEST_LUL       flameblast12  Private 2024-12-12   \n",
      "1         The dark guy  76561199090609673  Private 2024-12-12   \n",
      "2              SpamNik  76561198846896790  Private 2024-12-12   \n",
      "3    Jerry's Bait Shop         Mcslappy56  Private 2024-12-12   \n",
      "4                larry  76561199513668747  Private 2024-12-12   \n",
      "..                 ...                ...      ...        ...   \n",
      "65           ScottySee  76561199183489661  Private 2024-11-12   \n",
      "66      Multiversalboi  76561199523203961  Private 2024-11-12   \n",
      "67            Neo_Cat3  76561199062398344  Private 2024-11-12   \n",
      "68  Ricomincio da Capa         BananaSpia  Private 2024-11-12   \n",
      "69           Koshak UA         DIMA097097  Private 2024-11-12   \n",
      "\n",
      "    positive rating                                             review  \n",
      "0              True                 ì¡°ìž‘ì´ í”¼ìžíƒ€ì›Œëž‘ ë‹¬ë¼ì„œ ì ì‘í•˜ê¸° ì–´ë ¤ì› ëŠ”ë° ë„íŒŒë¯¼ë½•ì€ ì£½ì—¬ì¤Œ  \n",
      "1              True                       Think pizza tower but BETTER  \n",
      "2              True  Ð“Ñ€Ð° Ð²Ð°Ñ€Ñ‚Ð° ÑÐ²Ð¾Ñ—Ñ… 415 Ð³Ñ€Ð¸Ð²ÐµÐ½ÑŒ, Ð¾ÑÐºÑ–Ð»ÑŒÐºÐ¸ Ð² Ð½ÐµÑ— Ñ†Ñ–...  \n",
      "3              True  Probably the best 2d platformer I've played in...  \n",
      "4              True                                        goodc xaame  \n",
      "..              ...                                                ...  \n",
      "65             True  Great controls that are easy to learn but hard...  \n",
      "66             True                     Togetherâ€¦ we areâ€¦ AntonBLAST ðŸ’¥  \n",
      "67             True                                               paul  \n",
      "68             True  mhmmmhm satan butt ass naked,,.. yummy... mhmh...  \n",
      "69             True  ÐÐÐ™ÐšÐ ÐÐ©Ð Ð¤ÐÐ Ð“Ð Ð ÐŸÐž Ð’ÐÐ Ð†ÐžÐ›Ð•ÐÐ”Ð£, Ð Ð•ÐšÐžÐœÐ•ÐÐ”Ð£Ð® 100...  \n",
      "\n",
      "[70 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import pandas as pd\n",
    "\n",
    "# This will generate a wordcloud for the reviews of 'Antonblast' (app_id = 1887400)\n",
    "# Load the data into a pandas dataframe\n",
    "df = pd.read_json(\"1887400.json\")\n",
    "print(pd)\n",
    "\n",
    "# Join all the reviews into a single string.\n",
    "word_string = ' '.join(df['review']).replace('game', '')\n",
    "\n",
    "# Run through a regex made up for frequently used words that don't add value to the wordcloud.\n",
    "pointless_words = r'\\b(game|gameplay|played|play|playing|player|games)\\b' \n",
    "word_string = re.sub(pointless_words, '', word_string, flags=re.IGNORECASE)\n",
    "\n",
    "# Generate the wordcloud and display it.\n",
    "wordcloud = WordCloud(width=1920, height=1080).generate(word_string)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.gcf().set_size_inches(20, 10)\n",
    "plt.axis('off')\n",
    "plt.title('Wordcloud of Reviews for Antonblast')\n",
    "plt.show()\n",
    "\n",
    "# This will generate a pie chart of the countries of the reviewers of\n",
    "# 'Antonblast' (app_id = 1887400) (with smaller values grouped as 'Other' and \n",
    "# any private profiles excluded)\n",
    "df = pd.read_json(\"1887400.json\")\n",
    "df = df[df['country'] != 'Private']\n",
    "countries = df['country'].value_counts()\n",
    "countries = countries[countries > len(df)*0.025]\n",
    "countries['Other'] = len(df) - countries.sum()\n",
    "countries.plot.pie(autopct='%1.1f%%')\n",
    "plt.title('Distribution of Reviewers by Country for Antonblast')\n",
    "plt.ylabel('')\n",
    "plt.gcf().set_size_inches(10, 10)\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# This will generate a stacked bar graph comparing the number of positive reviews between 'Marvel Rivals' \n",
    "# (app_id = 2767030) and 'Overwatch 2' (app_id = 2357570)\n",
    "# Create a stacked bar graph comparing the number of positive and negative reviews between 'Marvel Rivals' and 'Overwatch 2'\n",
    "\n",
    "df_marvel = pd.read_json(\"2767030.json\")\n",
    "df_overwatch = pd.read_json(\"2357570.json\")\n",
    "\n",
    "pos_marvel = len(df_marvel[df_marvel['positive rating']])\n",
    "neg_marvel = len(df_marvel) - pos_marvel\n",
    "\n",
    "pos_marvel_pct = pos_marvel / len(df_marvel) * 100\n",
    "neg_marvel_pct = 100 - pos_marvel_pct\n",
    "\n",
    "pos_overwatch = len(df_overwatch[df_overwatch['positive rating']])\n",
    "neg_overwatch = len(df_overwatch) - pos_overwatch\n",
    "\n",
    "pos_overwatch_pct = pos_overwatch / len(df_overwatch) * 100\n",
    "neg_overwatch_pct = 100 - pos_overwatch_pct\n",
    "\n",
    "df_pos_neg = pd.DataFrame({\n",
    "    'Marvel Rivals \\n(Based on ' + str(len(df_marvel)) + ' reviews)': [pos_marvel_pct, neg_marvel_pct],\n",
    "    'Overwatch 2 \\n(Based on ' + str(len(df_overwatch)) + ' reviews)': [pos_overwatch_pct, neg_overwatch_pct]\n",
    "}, index=['Positive', 'Negative'])\n",
    "\n",
    "df_pos_neg.T.plot(kind='bar', stacked=True, color=['green', 'red'], rot=0)\n",
    "plt.title('Comparison of Positive and Negative Review Distribution for Marvel Rivals and Overwatch 2')\n",
    "plt.xlabel('Game')\n",
    "plt.ylabel('Percentage of Reviews')\n",
    "plt.legend(title='Review Type')\n",
    "plt.gcf().set_size_inches(10, 7)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae694cd-f0e4-40df-94e6-e374305e8b71",
   "metadata": {},
   "source": [
    "<b>Project Management Reflection</b>\n",
    "\n",
    "In terms of timeliness, I believe I stayed fairly on track due to the structure of the course going through the content at a very steady and structured pace. Each lab I would finish essentially always where I was meant to be and ready to continue on with the project. I found this a little frustrating and hard to work with personally as at times I felt as though the actual reason I was completing the assigned work was unclear which would ultimately mean when the nature of the project was fully revealed, I would most likely have to go back to refactor a lot of stuff or perhaps change direction entirely to ensure my project was better suited to what was expected of us. \n",
    "In terms of managing the code base, I found that the project wasnâ€™t too large and thus not too hard to handle. I actually mainly wrote out the code without really considering any functions etc. then while the code was still fresh in my head, went back to refactor sections into methods and such. This was to ensure that when I came back to the project each week, I would avoid having to spend time reading over the code base to understand where I was at since all of my methods were clearly named to essentially read the main body of the program like a set of instructions. I also decided to make the two jupyter notebook cells for the BS4 version and selenium version able to run independently of each other just to ensure no errors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d941797-c8b7-4ba5-a012-166ba78ac154",
   "metadata": {},
   "source": [
    "<b> Process Reflection </b>\n",
    "\n",
    "Week 1: I started off with deciding what to do for the project and ended up basing it on a similar program I had worked on prior (A program made to scrape workshop items for 'Human Fall Flat'). I started with setting up BS4 and writing a simple script to grab review boxes to just ensure I was able to grab the necessary info. I realised that due to the layout of Steamâ€™s website, I wouldnâ€™t be able to grab more than ten reviews. This meant I would have to make use of Selenium to enable me to interact with the browser.\n",
    "\n",
    "Week 2: I received feedback on my idea and a suggestion of using the reviews to visualise data in the way of a wordcloud based on reviews. I began to refine my program and start implementing methods to clean the data.\n",
    "\n",
    "Week 3: I had the data cleaned and began to look into the documentation for libraries like â€˜matplotlibâ€™, â€˜pandasâ€™, and â€˜wordcloudâ€™. These would enable me to create the visualisations I was looking to make.\n",
    "\n",
    "Week 4: I had everything I needed and began going back through my code to refactor where necessary to ensure better readability and better modularity etc.\n",
    "\n",
    "Week 5: At this point, I was mainly just choosing what games to base my data on and allowing my program to run to gather mass amounts of data. I did have an idea to improve my selenium version by using it in tandem with Beautiful Soup. I have a theory that grabbing the entire DOM with Selenium and parsing it with Beautiful Soup would prove faster than handling everything with Selenium. I feel this is not high priority though, and due to the amount of coursework due a the time, I decided to pass on it.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-programming-for-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
